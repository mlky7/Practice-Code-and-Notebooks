{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0adf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') \n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b742ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((264, 9), (627, 9))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfeval.shape, dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "500a46e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                    object\n",
       "age                   float64\n",
       "n_siblings_spouses      int64\n",
       "parch                   int64\n",
       "fare                  float64\n",
       "class                  object\n",
       "deck                   object\n",
       "embark_town            object\n",
       "alone                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c83e697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Southampton', 'Cherbourg', 'Queenstown', 'unknown'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain[\"embark_town\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d588f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"sex\",\"n_siblings_spouses\",\"parch\",\"class\",\"deck\",\n",
    "                       \"embark_town\",\"alone\"]\n",
    "NUMERIC_COLUMNS = [\"age\",\"fare\"]\n",
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd2fb5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(np.int64(1), np.int64(0), np.int64(3), np.int64(4), np.int64(2), np.int64(5), np.int64(8)), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='parch', vocabulary_list=(np.int64(0), np.int64(1), np.int64(2), np.int64(5), np.int64(3), np.int64(4)), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63555f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(np.int64(1), np.int64(0), np.int64(3), np.int64(4), np.int64(2), np.int64(5), np.int64(8)), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='parch', vocabulary_list=(np.int64(0), np.int64(1), np.int64(2), np.int64(5), np.int64(3), np.int64(4)), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype = tf.float32))\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "657c6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e91bd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain_encoded = pd.get_dummies(dftrain)\n",
    "dfeval_encoded = pd.get_dummies(dfeval)\n",
    "\n",
    "dftrain_encoded, dfeval_encoded = dftrain_encoded.align(dfeval_encoded,\n",
    "                                                        join=\"left\",\n",
    "                                                        axis=1,\n",
    "                                                        fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cad785f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_function(data_df, label_df, num_epochs = EPOCHS, shuffle = True, batch_size = BATCH):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "train_ds = input_function(dftrain,y_train)\n",
    "eval_ds = input_function(dfeval, y_eval, shuffle=False)\n",
    "\n",
    "X_train = dftrain_encoded.to_numpy().astype(\"float32\")\n",
    "X_eval = dfeval_encoded.to_numpy(\"float32\")\n",
    "y_train_np = y_train.to_numpy(\"float32\")\n",
    "y_eval_np = y_eval.to_numpy(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a9ab6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jewel\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6415 - loss: 9.0442 - val_accuracy: 0.6250 - val_loss: 6.0507\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6154 - loss: 7.9842 - val_accuracy: 0.6250 - val_loss: 5.5493\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5962 - loss: 8.8585 - val_accuracy: 0.6136 - val_loss: 5.0637\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5770 - loss: 6.6992 - val_accuracy: 0.6061 - val_loss: 4.6459\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5716 - loss: 6.0631 - val_accuracy: 0.5682 - val_loss: 4.2873\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5295 - loss: 5.5651 - val_accuracy: 0.5417 - val_loss: 3.9744\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4969 - loss: 4.9361 - val_accuracy: 0.4583 - val_loss: 3.7157\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4617 - loss: 4.0789 - val_accuracy: 0.4432 - val_loss: 3.4957\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4107 - loss: 4.7432 - val_accuracy: 0.4432 - val_loss: 3.2682\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4264 - loss: 4.6538 - val_accuracy: 0.4091 - val_loss: 3.0607\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4037 - loss: 3.4922 - val_accuracy: 0.3977 - val_loss: 2.8625\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4161 - loss: 3.8027 - val_accuracy: 0.4053 - val_loss: 2.6586\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3715 - loss: 3.4738 - val_accuracy: 0.4015 - val_loss: 2.4667\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3950 - loss: 2.9652 - val_accuracy: 0.3864 - val_loss: 2.2635\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4152 - loss: 2.6713 - val_accuracy: 0.4053 - val_loss: 2.0582\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3967 - loss: 2.8041 - val_accuracy: 0.4129 - val_loss: 1.8530\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4540 - loss: 2.1965 - val_accuracy: 0.4129 - val_loss: 1.6655\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4420 - loss: 2.0625 - val_accuracy: 0.4356 - val_loss: 1.4765\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4604 - loss: 1.5906 - val_accuracy: 0.4470 - val_loss: 1.2948\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4581 - loss: 1.4913 - val_accuracy: 0.4886 - val_loss: 1.1252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x298f62819a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid', input_shape = (X_train.shape[1],))\n",
    "])\n",
    "\n",
    "model.compile(optimizer = \"adam\", \n",
    "              loss = \"binary_crossentropy\",\n",
    "               metrics = [\"accuracy\"])\n",
    "model.fit(X_train, y_train_np,\n",
    "         epochs = EPOCHS, \n",
    "         batch_size = BATCH, \n",
    "          validation_data = (X_eval, y_eval_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31981714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5196 - loss: 1.0357 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1251825094223022, 0.4886363744735718]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(X_eval, y_eval_np)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b15a0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4886363744735718"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1] #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "      sex   age   class  survived\n",
      "0    male  35.0   Third  0.572147\n",
      "1    male  54.0   First  0.329082\n",
      "2  female  58.0   First  0.886741\n",
      "3  female  55.0  Second  0.824631\n",
      "4    male  34.0  Second  0.641993\n",
      "5  female  15.0   Third  0.462792\n",
      "6  female   8.0   Third  0.302254\n",
      "7    male  21.0   Third  0.372083\n",
      "8  female  18.0   Third  0.556858\n",
      "9  female  19.0   Third  0.523437\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result = model.predict(X_eval).flatten()\n",
    "\n",
    "dfeval = dfeval.copy()\n",
    "dfeval[\"survived\"] = result\n",
    "print(dfeval[['sex', 'age', 'class', 'survived']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4415931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.55      0.57       165\n",
      "         1.0       0.34      0.38      0.36        99\n",
      "\n",
      "    accuracy                           0.49       264\n",
      "   macro avg       0.47      0.47      0.47       264\n",
      "weighted avg       0.50      0.49      0.49       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary = (np.array(result) > 0.5).astype(int).flatten()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_eval_np, y_pred_binary))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
